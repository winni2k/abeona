import gzip
import json
import shutil
from pathlib import Path
import logging

from Bio import SeqIO

logging.basicConfig()
logging.getLogger().setLevel(logging.INFO)


import cortexpy.graph.parser.streaming

with open('args.json') as fh:
    ARGS = json.load(fh)

FASTX_INPUT = {
    'forward': ARGS['fastx_forward'],
    'reverse': ARGS['fastx_reverse'],
    'single': ARGS['fastx_single'],
}

KALLISTO_INPUT = {
    'forward': ARGS['kallisto_fastx_forward'],
    'reverse': ARGS['kallisto_fastx_reverse'],
    'single': ARGS['kallisto_fastx_single'],
}

MCCORTEX = f'mccortex {ARGS["kmer_size"]}'
MCCORTEX_ARGS = f'--sort --force -m {ARGS["memory"]}G'
if ARGS['quiet']:
    MCCORTEX_ARGS += ' --quiet'

rule all:
    input:
        'cortex_graph/full.clean.ctx',
        dynamic('transcripts/g{sg_id}.transcripts.fa.gz'),


rule full_cortex_graph:
    input: [v for v in FASTX_INPUT.values() if v is not None]
    output: 'cortex_graph/full.ctx'
    threads: 16
    run:
        cmd = [MCCORTEX, 'build', MCCORTEX_ARGS, '--threads', threads, '--kmer', ARGS['kmer_size'],
               '--sample', 'abeona']
        if FASTX_INPUT['forward'] is not None:
            cmd += ['--seq2', f'{FASTX_INPUT["forward"]}:{FASTX_INPUT["reverse"]}']
        if FASTX_INPUT['single'] is not None:
            cmd += ['--seq', FASTX_INPUT['single']]
        cmd.append(output)
        cmd = [str(c) for c in cmd]
        shell(' '.join(cmd))

rule pruned_cortex_graph:
    input: 'cortex_graph/full.ctx'
    output: 'cortex_graph/full.clean.ctx'
    run:
        shell(f'{MCCORTEX} clean {MCCORTEX_ARGS}'
              f' -T0 -U{ARGS["min_unitig_coverage"]}'
              f' --out {output} {input}')

rule subgraph_cortex_graph:
    input: 'cortex_graph/full.clean.ctx'
    output: dynamic('cortex_subgraphs/g{sg_id}.ctx')
    threads: 16
    run:
        out_dir = 'cortex_subgraphs'
        cmd = f'python -m abeona subgraphs {input} {out_dir} -m {ARGS["memory"]} -c {threads}'
        if ARGS['initial_contigs'] is not None:
            cmd += f' --initial-contigs {ARGS["initial_contigs"]}'
        shell(cmd)

rule traverse_subgraphs:
    input: 'cortex_subgraphs/g{sg_id}.ctx'
    output: 'traversals/g{sg_id}.traverse.pickle'
    run:
        with open(str(input), 'rb') as fh:
            first_kmer = next(cortexpy.graph.parser.streaming.kmer_string_generator_from_stream(fh))
        shell(f'cortexpy traverse --graph {input} --out {output} {first_kmer}')

rule pruned_subgraphs:
    input:  'traversals/g{sg_id}.traverse.pickle',
    output:  'pruned_traversals/g{sg_id}.traverse.pickle'
    run:
        shell(f'cortexpy prune --out {output} {input} --remove-tips {ARGS["min_tip_length"]}')

rule candidate_transcripts:
    input: 'pruned_traversals/g{sg_id}.traverse.pickle'
    output: 'candidate_transcripts/g{sg_id}.transcripts.fa.gz'
    run:
        output_tmp = str(output) + '.tmp'
        shell(f'cortexpy view traversal {input} | gzip -c > {output_tmp}')
        shutil.move(output_tmp, str(output))

rule build_kallisto_index:
    input:  'candidate_transcripts/g{sg_id}.transcripts.fa.gz'
    output: 'kallisto_indices/g{sg_id}.transcripts.ki'
    run:
        cmd = 'kallisto index -i {output} {input}'
        if int(ARGS['kmer_size']) < 31:
            cmd += f' --kmer-size {ARGS["kmer_size"]}'
        shell(cmd)

rule kallisto_quant:
    input:
        index='kallisto_indices/g{sg_id}.transcripts.ki',
        fastxs=[v for v in KALLISTO_INPUT.values() if v is not None]
    output:
        ['kallisto_quant/g{sg_id}/bs_abundance_'+ str(i) + '.tsv' for i in range(ARGS['bootstrap_samples'])],
    run:
        out_dir = Path(output[0]).parent
        cmd = (f'kallisto quant -i {input.index} --output-dir {out_dir}'
               f' -b {ARGS["bootstrap_samples"]} --plaintext')
        if ARGS['kallisto_fastx_forward'] is not None:
            cmd += f' {ARGS["kallisto_fastx_forward"]} {ARGS["kallisto_fastx_reverse"]}'
        else:
            cmd += (
                f' -l {ARGS["kallisto_fragment_length"]} -s {ARGS["kallisto_sd"]}'
                f' --single {ARGS["kallisto_fastx_single"]}'
            )
        shell(cmd)

def filter_and_annotate_contigs(filtered_counts, candidate_transcripts):
    with gzip.open(str(candidate_transcripts), 'rt') as fh:
        for record in SeqIO.parse(fh, "fasta"):
            if record.id in filtered_counts.index:
                record.description = 'prop_bs_est_counts_ge_1={}'.format(filtered_counts.at[record.id])
                yield record

rule filter_transcripts:
    input:
        abundance=['kallisto_quant/g{sg_id}/bs_abundance_' + f'{i}.tsv' for i in range(ARGS['bootstrap_samples'])],
        candidate_transcripts='candidate_transcripts/g{sg_id}.transcripts.fa.gz'
    output:'transcripts/g{sg_id}.transcripts.fa.gz'
    run:
        import pandas as pd
        import numpy as np
        logger = logging.getLogger('abeona.assembly.filter_transcripts')
        bootstraps = []
        for bs_abundance in input.abundance:
            bootstraps.append(
                pd.read_csv(bs_abundance, sep='\t', dtype={'target_id': str, 'length': int}))
        bootstraps = pd.concat(bootstraps)
        est_count_threshold = 1
        keep_prop = 0.95
        ge1_counts = bootstraps.groupby('target_id')['est_counts'].aggregate(
        lambda x: np.sum(x >= est_count_threshold) / len(x))

        keep_counts = ge1_counts[ge1_counts >= keep_prop]

        logging.info(f'Keeping contigs with >= {keep_prop} of bootstrapped est_counts >= {est_count_threshold}')
        logger.info(f'keeping {len(keep_counts)} out of {len(ge1_counts)} contigs.')

        filtered_records = filter_and_annotate_contigs(keep_counts, input.candidate_transcripts)
        logger.info(f'Writing filtered records to {output}')
        with gzip.open(str(output), 'wt') as fh:
            SeqIO.write(filtered_records, fh, "fasta")
